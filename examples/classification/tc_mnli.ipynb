{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "### Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Task Deep Neural Networks for Natural Language Understanding  \n",
    "\n",
    "\n",
    "This PyTorch package implements the Multi-Task Deep Neural Networks (MT-DNN) for Natural Language Understanding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data  \n",
    "\n",
    "This notebook assumes you have data already pre-processed in the MT-DNN format and accessible in a local directory.  \n",
    "\n",
    "\n",
    "For the purposes of this example we have added sample data that is already processed in MT-DNN format which can be found in the __sample_data__ folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from mtdnn.common.types import EncoderModelType\n",
    "from mtdnn.configuration_mtdnn import MTDNNConfig\n",
    "from mtdnn.modeling_mtdnn import MTDNNModel\n",
    "from mtdnn.process_mtdnn import MTDNNDataProcess\n",
    "from mtdnn.tasks.config import MTDNNTaskDefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Configuration, Tasks and Model Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../sample_data/bert_uncased_lower/mnli/\"\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Configuration Object \n",
    "\n",
    "Create a model configuration object, `MTDNNConfig`, with the necessary parameters to initialize the MT-DNN model. Initialization without any parameters will default to a similar configuration that initializes a BERT model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = MTDNNConfig(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create Task Definition Object  \n",
    "\n",
    "Define the task parameters to train for and initialize an `MTDNNTaskDefs` object. Create a task parameter dictionary. Definition can be a single or multiple tasks to train.  `MTDNNTaskDefs` can take a python dict, yaml or json file with task(s) defintion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Mapping Task attributes\n",
      "INFO - Configured task definitions - ['mnli']\n"
     ]
    }
   ],
   "source": [
    "tasks_params = {\n",
    "        \"mnli\": {\n",
    "            \"data_format\": \"PremiseAndOneHypothesis\",\n",
    "            \"encoder_type\": \"BERT\",\n",
    "            \"dropout_p\": 0.3,\n",
    "            \"enable_san\": True,\n",
    "            \"labels\": [\"contradiction\", \"neutral\", \"entailment\"],\n",
    "            \"metric_meta\": [\"ACC\"],\n",
    "            \"loss\": \"CeCriterion\",\n",
    "            \"kd_loss\": \"MseCriterion\",\n",
    "            \"n_class\": 3,\n",
    "            \"split_names\": [\n",
    "                \"train\",\n",
    "                \"matched_dev\",\n",
    "                \"mismatched_dev\",\n",
    "                \"matched_test\",\n",
    "                \"mismatched_test\",\n",
    "            ],\n",
    "            \"task_type\": \"Classification\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "# Define the tasks\n",
    "task_defs = MTDNNTaskDefs(tasks_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Create the Data Processing Object  \n",
    "\n",
    "Create a data preprocessing object, `MTDNNDataProcess`. This creates the training, test and development PyTorch dataloaders needed for training and testing. We also need to retrieve the necessary training options required to initialize the model correctly, for all tasks.  \n",
    "\n",
    "Define a data process that handles creating the training, test and development PyTorch dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Starting to process the training data sets\n",
      "INFO - Loading ../../sample_data/bert_uncased_lower/mnli/mnli_train.json as task 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 392702 samples out of 392702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Starting to process the testing data sets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 9832 samples out of 9832\n",
      "Loaded 9847 samples out of 9847\n",
      "Loaded 9815 samples out of 9815\n",
      "Loaded 9796 samples out of 9796\n"
     ]
    }
   ],
   "source": [
    "# Make the Data Preprocess step and update the config with training data updates\n",
    "data_processor = MTDNNDataProcess(\n",
    "    config=config,\n",
    "    task_defs=task_defs,\n",
    "    data_dir=DATA_DIR,\n",
    "    train_datasets_list=[\"mnli\"],\n",
    "    test_datasets_list=[\"mnli_mismatched\", \"mnli_matched\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the processed batch multitask batch data loaders for training, development and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "multitask_train_dataloader = data_processor.get_train_dataloader()\n",
    "dev_dataloaders_list = data_processor.get_dev_dataloaders()\n",
    "test_dataloaders_list = data_processor.get_test_dataloaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get training options to initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_opts = data_processor.get_decoder_options_list()\n",
    "task_types = data_processor.get_task_types_list()\n",
    "dropout_list = data_processor.get_tasks_dropout_prob_list()\n",
    "loss_types = data_processor.get_loss_types_list()\n",
    "kd_loss_types = data_processor.get_kd_loss_types_list()\n",
    "tasks_nclass_list = data_processor.get_task_nclass_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us update the batch steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_all_batches = data_processor.get_num_all_batches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the MTDNN Model\n",
    "\n",
    "Now we can go ahead and create an `MTDNNModel` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, number of task labels: 3\n"
     ]
    }
   ],
   "source": [
    "model = MTDNNModel(\n",
    "    config,\n",
    "    task_defs,\n",
    "    pretrained_model_name=\"bert-base-uncased\",\n",
    "    num_train_step=num_all_batches,\n",
    "    decoder_opts=decoder_opts,\n",
    "    task_types=task_types,\n",
    "    dropout_list=dropout_list,\n",
    "    loss_types=loss_types,\n",
    "    kd_loss_types=kd_loss_types,\n",
    "    tasks_nclass_list=tasks_nclass_list,\n",
    "    multitask_train_dataloader=multitask_train_dataloader,\n",
    "    dev_dataloaders_list=dev_dataloaders_list,\n",
    "    test_dataloaders_list=test_dataloaders_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on one epoch and predict using the training and test  \n",
    "\n",
    "At this point the MT-DNN model allows us to fit to the model and create predictions. The fit takes an optional `epochs` parameter that overwrites the epochs set in the `MTDNNConfig` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(epoch=1)\n",
    "model.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain predictions with a previously trained model checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predict function can take an optional checkpoint, `trained_model_chckpt`. This can be used for inference and running evaluations on an already trained PyTorch MT-DNN model.  \n",
    "Optionally using a previously trained model as checkpoint.  \n",
    "\n",
    "```Python\n",
    "# Predict using a MT-DNN model checkpoint\n",
    "checkpt = \"<path_to_existing_model_checkpoint>\"\n",
    "model.predict(trained_model_chckpt=checkpt)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_gpu)",
   "language": "python",
   "name": "nlp_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
